{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWGQDbroKKRg"
      },
      "source": [
        "<b><h1><center>Data Preparation for 1D IR Spectrum</center><h1><b>\n",
        "<h3><center>Tipsi Jadav: 201801091</center></h3>\n",
        "<h3><center>Ujas Thakkar: 201801112</center></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg2U4O3aM0Z-"
      },
      "source": [
        "# 1. Absorption Spectrum \n",
        "Absorption spectrum is calculated by the formula:<br>\n",
        "$I(\\omega) = \\sum_{k=1}^{N} \\mu_k^2F_k(E_k - \\omega)$\n",
        "<br>\n",
        "<br>\n",
        "Where k runs over all relevant excited states of the system, $μ_k$ are the absolute values of the transition dipole moments, $E_k$ are excited-state energies, and $F_k(\\omega)$ are the gaussian line-shape functions.\n",
        "<br>\n",
        "<br>\n",
        "In our calculations, we consider a gaussian line-shape function:<br>\n",
        "$F_k(\\omega) = e^\\frac{-\\omega^2}{2\\sigma_k^2}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN2LLJ2ROlEp"
      },
      "source": [
        "# 2. Target System\n",
        "The target system is thus specified by parameters:<br>\n",
        "$(E_k, μ_k), \\;\\; k = 1, 2, 3 ... N$\n",
        "<br>\n",
        "<br>\n",
        "Each spectrum $I(\\omega)$ is specified by parameters:<br>\n",
        "$(E_k, μ_k, \\sigma_k), \\;\\; k = 1, 2, 3 ... N$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d-PtKINYj6O"
      },
      "source": [
        "# 3. Other Systems\n",
        "Other systems labeled by $a, a = 1, ..., M$ are characterized by $(E_k^{(a)}, μ_k^{(a)})$ where $E_k^{(a)}$, $μ_k^{(a)}$ differ from the corresponding $E_k$, $μ_k$ of the target system within say $±20^{-cm}$.\n",
        "<br>\n",
        "<br>\n",
        "Each other system is thus specified by parameters:<br>\n",
        "$(E_k^{(a)}, μ_k^{(a)}), \\;\\; k = 1, 2, 3 ... N$\n",
        "<br>\n",
        "<br>\n",
        "Mathematically, these parameters can be obtained from those of the target system as:\n",
        "- $E_n^{(a)} \\,\\to\\, E(1 + \\delta_n^{(a)})$. Here $\\delta_n$ is a random number whose absoulute value is in the range $\\delta_n \\leq 20$.\n",
        "- $\\mu_n \\,\\to\\, \\mu(1 + \\delta_n^{(a)})$\\. Here $\\delta_n$ is a random number whose absoulute value is in the range $\\delta_n \\leq 5\\%$ of $μ$.\n",
        "\n",
        "Each \"other\" spectrum $I^{(a)}(ω)$ is specified by parameters:<br>\n",
        "$(E_k^{(a)}, μ_k^{(a)}, \\sigma_k^{(a)}), \\;\\; k = 1, 2, 3 ... N$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edXmMks0q0kK"
      },
      "source": [
        "# 4. Generation of Target and \"Other\" Spectra\n",
        "In the evaluation of spectra, we also introduce random fluctuations of the intensity of the spectrum at each value of frequency $\\omega_j = \\omega_0 + j\\delta_\\omega$. The calculation thus goes as follows (we will use the target molecule as an example):\n",
        "- Create random $(E_k^{(a)}, μ_k^{(a)}, \\sigma_k^{(a)}), \\;\\; k = 1, 2, 3 ... N$\n",
        "- Run do-loop on $\\omega_j$\n",
        "- Calculate $I(\\omega_j ) = g_j  + \\sum_{k=1}^{N}μ_k^{2}F_k(E_k − ω_j)$ where $g_j$ is a random number whose absolute is in the range $g_j \\leq 0.5$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Asymmetry in Peaks\n",
        "In real scenario peaks are not perfectly gaussian: they have asymmetry. Realistic data consists of humps in a single peaks, which implies the resultant peak consists of numerous peaks with various widths and positions, this results in asymmetry. The following equation can be used to determine this asymmetry mathematically.<br>\n",
        "$F_k = A_l \\cdot 𝐹_𝑘(𝐸_𝑘−ω-S_l) + 𝐹_𝑘(𝐸_𝑘−ω) + A_r \\cdot 𝐹_𝑘(𝐸_𝑘−ω+S_r)\\div 3$<br>\n",
        "Where $F_k()$ is a gaussian line-shape function, $S_l/S_r$ are shift introduced in gaussian line-shape function for a given $ω$ and $A_l/A_r$ are amplitude of the shifts introduced.\n",
        "<br>\n",
        "<br>\n",
        "Asymmetry in IR spectra can be introduced using one of two methods.\n",
        "\n",
        "## 5.1 Method - 1\n",
        "Introduce either left or right shift in the IR spectra. Mathematically this can be represented by one of the two formulas.<br>\n",
        "$F_k = A_l\\cdot𝐹_𝑘(𝐸_𝑘−ω-S_l) + 𝐹_𝑘(𝐸_𝑘−ω)\\div 2$<br>\n",
        "$F_k = 𝐹_𝑘(𝐸_𝑘−ω) + A_r\\cdot𝐹_𝑘(𝐸_𝑘−ω+S_r)\\div 2$\n",
        "\n",
        "## 5.2 Method - 2\n",
        "Both left and right shift will be introduced in this method, but the overall shift will not exceed some value T, mathematically speaking:<br>\n",
        "$F_k = A_l\\cdot𝐹_𝑘(𝐸_𝑘−ω-S_l) + 𝐹_𝑘(𝐸_𝑘−ω) + A_r\\cdot𝐹_𝑘(𝐸_𝑘−ω+S_r)\\div 3$, where $S_l + S_r \\leq T$."
      ],
      "metadata": {
        "id": "ja5StADYCShN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xXzMt-3r0wKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5bed9c-2dbf-4d74-8ff8-2621a4717cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4ecrYsH4cBvk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5exh63Y0zxdC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c0d219b3-e971-4f01-c355-8fad1317139d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef plot(x, y, save, data_no, i):\\n  plt.figure(figsize=(12, 6))\\n\\n  plt.plot(x, y)\\n\\n  if save == 1:\\n    plt.savefig(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/{data_no}/{i + 1}.png\")\\n  else:\\n    plt.savefig(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/{data_no}/{i + 1}.png\")\\n\\n  plt.show()\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "def plot(x, y, save, data_no, i):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  plt.plot(x, y)\n",
        "\n",
        "  if save == 1:\n",
        "    plt.savefig(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/{data_no}/{i + 1}.png\")\n",
        "  else:\n",
        "    plt.savefig(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/{data_no}/{i + 1}.png\")\n",
        "\n",
        "  plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fxUn03Kfsbbv"
      },
      "outputs": [],
      "source": [
        "def gaussian_lineshape(E, sig, shift, w):\n",
        "  Fk = []\n",
        "  for i in range(len(E)):\n",
        "    num = -((w - E[i] + shift[i])**2)\n",
        "    deno  = 2*((sig[i])**2)\n",
        "\n",
        "    temp = np.exp((num)/(deno))\n",
        "    Fk.append(temp)\n",
        "\n",
        "  Fk = np.array(Fk)\n",
        "\n",
        "  return Fk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QCO9mLZXcHZB"
      },
      "outputs": [],
      "source": [
        "def data_generation_constraints(M, W, E0, mu0, sig0, gaussian_shift, gaussian_amp):  \n",
        "\n",
        "  ir_data = []\n",
        "  for i in range(M): \n",
        "    # this adds noise to the Ek values\n",
        "    delta = np.random.uniform(low=-20, high=20, size=(len(E0)))\n",
        "    E = E0 - delta\n",
        "\n",
        "    # this adds noise to the uk values\n",
        "    delta = np.random.uniform(low=0, high=0.05, size=(len(mu0)))\n",
        "    mu = mu0*(1 + delta)\n",
        "\n",
        "    if(random.randint(0,1) == 0):\n",
        "      shiftl = gaussian_shift*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "      shiftr = (gaussian_shift-shiftl)*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "    else:\n",
        "      shiftr = gaussian_shift*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "      shiftl = (gaussian_shift-shiftr)*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "\n",
        "    #this controls amplitude of the subpeaks\n",
        "    ampl = 1 + gaussian_amp*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "    ampr = 1 + gaussian_amp*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "\n",
        "    ir = []\n",
        "    for j in range(len(W)): \n",
        "      #subpeak on the centre\n",
        "      Fkc = gaussian_lineshape(E, sig0, np.zeros(len(E0)), W[j])\n",
        "\n",
        "      #subpeak on the left side, which depends on the subpeak on the center\n",
        "      Fkl = ampl*gaussian_lineshape(E, sig0, -shiftl, W[j])\n",
        "\n",
        "      #subpeak on the right side, which also depends on the subpeal on the center\n",
        "      Fkr = ampr*gaussian_lineshape(E, sig0, shiftr, W[j])\n",
        "\n",
        "      # #resultant peak(noisey)\n",
        "      Fk = (Fkl + Fkc + Fkr)/3\n",
        "      \n",
        "      uk2 = mu**2\n",
        "\n",
        "      #calculation of absorption spectra\n",
        "      Iw_n = np.sum(uk2*Fk)\n",
        "\n",
        "      ir.append(Iw_n) \n",
        " \n",
        "    ir_data.append(ir)\n",
        "    # plot(W, ir, save, data_no, i)\n",
        "\n",
        "  return np.array(ir_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gi0FQZv30fa4"
      },
      "outputs": [],
      "source": [
        "def data_generation_without_constraints(M, W, E0, mu0, sig0, gaussian_shift, gaussian_amp):  \n",
        "\n",
        "  ir_data = []\n",
        "  for i in range(M): \n",
        "    # this adds noise to the Ek values\n",
        "    delta = np.random.uniform(low=-20, high=20, size=(len(E0)))\n",
        "    E = E0 - delta\n",
        "\n",
        "    # this adds noise to the uk values\n",
        "    delta = np.random.uniform(low=0, high=0.05, size=(len(mu0)))\n",
        "    mu = mu0*(1 + delta)\n",
        "\n",
        "    choice = random.randint(0,1)\n",
        "\n",
        "    if(choice == 0):\n",
        "      shiftl = gaussian_shift*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "    else:\n",
        "      shiftr = gaussian_shift*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "\n",
        "    #this controls amplitude of the subpeaks\n",
        "    ampl = 1 + gaussian_amp*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "    ampr = 1 + gaussian_amp*np.random.uniform(low=0, high=1, size=(len(E0)))\n",
        "\n",
        "    ir = []\n",
        "    for j in range(len(W)): \n",
        "      #subpeak on the centre\n",
        "      Fkc = gaussian_lineshape(E, sig0, np.zeros(len(E0)), W[j])\n",
        "\n",
        "      if choice == 0:\n",
        "        #subpeak on the left side, which depends on the subpeak on the center\n",
        "        Fkl = ampl*gaussian_lineshape(E, sig0, -shiftl, W[j])\n",
        " \n",
        "        Fk = (Fkl + Fkc)/2\n",
        "      else:\n",
        "        #subpeak on the right side, which also depends on the subpeal on the center\n",
        "        Fkr = ampr*gaussian_lineshape(E, sig0, shiftr, W[j])\n",
        "\n",
        "        Fk = (Fkc + Fkr)/2\n",
        "      \n",
        "      uk2 = mu**2\n",
        "\n",
        "      #calculation of absorption spectra\n",
        "      Iw_n = np.sum(uk2*Fk)\n",
        "\n",
        "      ir.append(Iw_n) \n",
        " \n",
        "    ir_data.append(ir)\n",
        "    # plot(W, ir, save, data_no, i)\n",
        "  \n",
        "  return np.array(ir_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iQDMnOp_Jv4n"
      },
      "outputs": [],
      "source": [
        "E0 = np.array([1723.9, 1495.4, 1229.2])\n",
        "mu0 = np.array([9.0, 7.9, 4.6])\n",
        "\n",
        "sig0 = np.array([15, 20, 25])\n",
        "\n",
        "gaussian_shift = 2.25*sig0 #this values are determined by trial and error\n",
        "\n",
        "Lambda = 0.03"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E_n = np.array([[0.1130, 0.6488, 0.7859],\n",
        "               [0.3010, 0.7178, 0.7567],\n",
        "               [0.8149, 0.8018, 0.2423],\n",
        "               [0.1755, 0.4216, 0.6776],\n",
        "               [0.6333, 0.8440, 0.9435]])\n",
        "\n",
        "mu_n = np.array([[0.4930, 0.9186, 0.0396],\n",
        "                 [0.7459, 0.9850, 0.0857],\n",
        "                 [0.1391, 0.2606, 0.2065],\n",
        "                 [0.9943, 0.7683, 0.7363],\n",
        "                 [0.4979, 0.4914, 0.2236]])\n",
        "\n",
        "sig_n = np.array([[0.1897, 0.9807, 0.6175],\n",
        "                  [0.1254, 0.2593, 0.8311],\n",
        "                  [0.8478, 0.2729, 0.2619],\n",
        "                  [0.6161, 0.9742, 0.0100],\n",
        "                  [0.5866, 0.6545, 0.2928]])"
      ],
      "metadata": {
        "id": "7iNuys20bdId"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = np.arange(1000, 2000, 0.5)\n",
        "\n",
        "for i in range(5):\n",
        "  E = E0*(1 + (Lambda*(E_n[i] - 0.5)))\n",
        "  mu = mu0*(1 + (Lambda*(mu_n[i] - 0.5)))\n",
        "  sig = sig0*(1 + (Lambda*(sig_n[i] - 0.5)))\n",
        "  \n",
        "  #Preparing training data\n",
        "  data1 = data_generation_constraints(120, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "  data2 = data_generation_without_constraints(120, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "\n",
        "  df1 = pd.DataFrame()\n",
        "  df2 = pd.DataFrame()\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df1[f\"{j}\"] = data1[:, j]\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df2[f\"{j}\"] = data2[:, j]\n",
        "\n",
        "  df1.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/w_0.5/train/{i}.csv\", header=True)\n",
        "  df2.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/w_0.5/train/{i}.csv\", header=True)\n",
        "\n",
        "  #Preparing validation data\n",
        "  data1 = data_generation_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "  data2 = data_generation_without_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "\n",
        "  df1 = pd.DataFrame()\n",
        "  df2 = pd.DataFrame()\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df1[f\"{j}\"] = data1[:, j]\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df2[f\"{j}\"] = data2[:, j]\n",
        "\n",
        "  df1.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/w_0.5/validation/{i}.csv\", header=True)\n",
        "  df2.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/w_0.5/validation/{i}.csv\", header=True)\n",
        "\n",
        "  #Preparing test data\n",
        "  data1 = data_generation_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "  data2 = data_generation_without_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "\n",
        "  df1 = pd.DataFrame()\n",
        "  df2 = pd.DataFrame()\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df1[f\"{j}\"] = data1[:, j]\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df2[f\"{j}\"] = data2[:, j]\n",
        "\n",
        "  df1.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/w_0.5/test/{i}.csv\", header=True)\n",
        "  df2.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/w_0.5/test/{i}.csv\", header=True)"
      ],
      "metadata": {
        "id": "GmWrWIAFtToX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = np.arange(1000, 2000, 1)\n",
        "\n",
        "for i in range(5):\n",
        "  E = E0*(1 + (Lambda*(E_n[i] - 0.5)))\n",
        "  mu = mu0*(1 + (Lambda*(mu_n[i] - 0.5)))\n",
        "  sig = sig0*(1 + (Lambda*(sig_n[i] - 0.5)))\n",
        "  \n",
        "  #Preparing training data\n",
        "  data1 = data_generation_constraints(120, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "  data2 = data_generation_without_constraints(120, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "\n",
        "  df1 = pd.DataFrame()\n",
        "  df2 = pd.DataFrame()\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df1[f\"{j}\"] = data1[:, j]\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df2[f\"{j}\"] = data2[:, j]\n",
        "\n",
        "  df1.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/w_1/train/{i}.csv\", header=True)\n",
        "  df2.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/w_1/train/{i}.csv\", header=True)\n",
        "\n",
        "  #Preparing validation data\n",
        "  data1 = data_generation_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "  data2 = data_generation_without_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "\n",
        "  df1 = pd.DataFrame()\n",
        "  df2 = pd.DataFrame()\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df1[f\"{j}\"] = data1[:, j]\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df2[f\"{j}\"] = data2[:, j]\n",
        "\n",
        "  df1.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/w_1/validation/{i}.csv\", header=True)\n",
        "  df2.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/w_1/validation/{i}.csv\", header=True)\n",
        "\n",
        "  #Preparing test data\n",
        "  data1 = data_generation_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "  data2 = data_generation_without_constraints(15, W, E, mu, sig, gaussian_shift, 0.5)\n",
        "\n",
        "  df1 = pd.DataFrame()\n",
        "  df2 = pd.DataFrame()\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df1[f\"{j}\"] = data1[:, j]\n",
        "\n",
        "  for j in range(len(W)):\n",
        "    df2[f\"{j}\"] = data2[:, j]\n",
        "\n",
        "  df1.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-1/w_1/test/{i}.csv\", header=True)\n",
        "  df2.to_csv(f\"/content/drive/MyDrive/BTP/Data/1D/data-2/w_1/test/{i}.csv\", header=True)"
      ],
      "metadata": {
        "id": "5qOhQ4tDUtyQ"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_preparation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}